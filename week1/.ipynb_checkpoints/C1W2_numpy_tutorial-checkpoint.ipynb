{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    '''\n",
    "    Compute sigmoid of x\n",
    "    x -- A scalar\n",
    "    s -- sigmoid of x\n",
    "    '''\n",
    "    \n",
    "    s = 1/(1+math.exp(-x))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# example of vector operation\n",
    "x = np.array([1,2,3])\n",
    "print(x+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    \n",
    "    s = 1/(1+np.exp(-x))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    s_ = s*(1-s)\n",
    "    \n",
    "    return s_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid_derivative(x) = [0.19661193 0.10499359 0.04517666]\n"
     ]
    }
   ],
   "source": [
    "# test sigmoid_derivative\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "print('sigmoid_derivative(x) = '+ str(sigmoid_derivative(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2vector(image):\n",
    "    v= image.reshape(np.prod(image.shape),1)\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nomalize Rows : Nomarlization often lead to a better performance \n",
    "# Normalize makes the gradient descent converges faster\n",
    "\n",
    "def normalizeRows(x):\n",
    "    xx = np.linalg.norm(x, axis=1, keepdims = True)\n",
    "    x_normalized = x/xx\n",
    "    \n",
    "    return x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0,3,4],[2,6,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:[[0.         0.6        0.8       ]\n",
      " [0.26726124 0.80178373 0.53452248]]\n"
     ]
    }
   ],
   "source": [
    "print('result:'+str(normalizeRows(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax function: softmax is one of a normalizing function used in \n",
    "# classification problem(classify two or more classes)\n",
    "# dividend need to be (nx,1)\n",
    "\n",
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    ex_sum = np.sum(ex, axis=1, keepdims = True)\n",
    "    \n",
    "    #print('Inside softmax function')\n",
    "    #print(ex)\n",
    "    #print(ex_sum)\n",
    "    \n",
    "    \n",
    "    return ex/ex_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax(x):[[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
      "  1.21052389e-04]\n",
      " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
      "  8.01252314e-04]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [9,2,5,0,0],[7,5,0,0,0]\n",
    "])\n",
    "\n",
    "print(\"softmax(x):\"+ str(softmax(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot = 278\n",
      " ---- Computation time = 0.22399999999977993\n",
      "outer = [[81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [63. 14. 14. 63.  0. 63. 14. 35.  0.  0. 63. 14. 35.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      " ---- Computation time = 0.5720000000000169\n",
      "elementwise multiplication = [81.  4. 10.  0.  0. 63. 10.  0.  0.  0. 81.  4. 25.  0.  0.]\n",
      " ---- Computation time = 0.36799999999992394\n",
      "gdot = [23.53951708 28.6598311  18.79312073]\n",
      " ---- Computation time = 0.3220000000001555\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# VECTORIZATION\n",
    "\n",
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### CLASSIC DOT PRODUCT OF VECTORS IMPLEMENTATION ###\n",
    "tic = time.process_time()\n",
    "dot = 0\n",
    "for i in range(len(x1)):\n",
    "    dot += x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print(\"dot = \" + str(dot)+ '\\n ---- Computation time = ' + str(1000*(toc-tic)))\n",
    "\n",
    "\n",
    "### CLASSIC OUTER PRODUCT IMPLEMENTATION ###\n",
    "tic = time.process_time()\n",
    "outer = np.zeros((len(x1),len(x2)))\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        outer[i,j] = x1[i]*x2[j]\n",
    "toc = time.process_time()\n",
    "print('outer = '+ str(outer) + '\\n ---- Computation time = '+ str(1000*(toc-tic)))\n",
    "\n",
    "### CLASSIC ELEMENTWISE IMPLEMENTATION\n",
    "tic = time.process_time()\n",
    "mul = np.zeros(len(x1))\n",
    "for i in range(len(x1)):\n",
    "    mul[i] = x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"elementwise multiplication = \" + str(mul) + \"\\n ---- Computation time = \"+ str(1000*(toc-tic)))\n",
    "\n",
    "### CLASSIC GENERAL DOT PRODUCT IMPLEMENTATION ###\n",
    "W = np.random.rand(3,len(x1))\n",
    "tic = time.process_time()\n",
    "gdot = np.zeros(W.shape[0])\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(len(x1)):\n",
    "        gdot[i] += W[i,j]*x1[j]\n",
    "toc = time.process_time()\n",
    "print('gdot = ' + str(gdot) + '\\n ---- Computation time = '+ str(1000*(toc-tic)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot= 278\n",
      " ---- Computation time = 0.000304000000000304\n"
     ]
    }
   ],
   "source": [
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### VECTORIZED DOT PRODUCT OF VECTORS ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(x1,x2)\n",
    "toc = time.process_time()\n",
    "print('dot= ' + str(dot) + '\\n ---- Computation time = '+ str(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer = [[81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [63 14 14 63  0 63 14 35  0  0 63 14 35  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      " ----- Computation time = 0.25999999999992696\n"
     ]
    }
   ],
   "source": [
    "### VECTORIZED OUTER PRODUCT ###\n",
    "tic = time.process_time()\n",
    "outer= np.outer(x1,x2)\n",
    "toc = time.process_time()\n",
    "print(\"outer = \" + str(outer) + \"\\n ----- Computation time = \"+ str(1000*(toc-tic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elementwise multiplication\n",
      "[81  4 10  0  0 63 10  0  0  0 81  4 25  0  0]\n",
      " ---- Computation time 0.1340000000000785\n"
     ]
    }
   ],
   "source": [
    "### Vectorized elementwise multiplication ###\n",
    "tic = time.process_time()\n",
    "mul = np.multiply(x1,x2)\n",
    "toc = time.process_time()\n",
    "print(\"elementwise multiplication\\n\"\n",
    "     + str(mul)+'\\n ---- Computation time '+ str(1000*(toc-tic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdot = [23.53951708 28.6598311  18.79312073]\n",
      " ----- Computation time = 0.14399999999969992\n"
     ]
    }
   ],
   "source": [
    "### VECTORIZED GENERAL DOT PRODUCT ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(W,x1)\n",
    "toc = time.process_time()\n",
    "print('gdot = ' + str(dot) + '\\n ----- Computation time = '+ str(1000*(toc-tic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK : IMPLEMENT THE L1 Loss function\n",
    "\n",
    "def L1(yhat, y):\n",
    "    \n",
    "    loss = np.abs(y - yhat)\n",
    "    loss_sum = np.sum(loss)githu\n",
    "    \n",
    "    return loss_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 1.1\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1 = \" + str(L1(yhat,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(yhat, y):\n",
    "\n",
    "    loss = np.sum((y-yhat)**2)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L2 = \" + str(L2(yhat,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 6.29500579 -6.14560418]\n",
      "  [ 0.57011457  4.72829825]]\n",
      "\n",
      " [[-6.0766493  21.48186903]\n",
      "  [15.90175904 -7.52082633]]\n",
      "\n",
      " [[-2.44860002 15.10338231]\n",
      "  [12.41943651 -2.43335875]]\n",
      "\n",
      " [[ 4.13199561 -6.369332  ]\n",
      "  [ 3.36230372  5.91818101]]\n",
      "\n",
      " [[ 7.68800362 -0.48743209]\n",
      "  [11.87217004 -9.95661289]]]\n",
      "[[ 6.29500579 -6.14560418]\n",
      " [ 0.57011457  4.72829825]\n",
      " [-6.0766493  21.48186903]\n",
      " [15.90175904 -7.52082633]\n",
      " [-2.44860002 15.10338231]\n",
      " [12.41943651 -2.43335875]\n",
      " [ 4.13199561 -6.369332  ]\n",
      " [ 3.36230372  5.91818101]\n",
      " [ 7.68800362 -0.48743209]\n",
      " [11.87217004 -9.95661289]]\n",
      "[[ 6.29500579 -6.14560418  0.57011457  4.72829825]\n",
      " [-6.0766493  21.48186903 15.90175904 -7.52082633]\n",
      " [-2.44860002 15.10338231 12.41943651 -2.43335875]\n",
      " [ 4.13199561 -6.369332    3.36230372  5.91818101]\n",
      " [ 7.68800362 -0.48743209 11.87217004 -9.95661289]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "arr = np.random.randn(5,2,2)*10 # (a,b,c) => (depth, height, width)\n",
    "print(arr)\n",
    "arr2 = arr.reshape(10,-1)\n",
    "print(arr2)\n",
    "print(arr.reshape(arr.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
